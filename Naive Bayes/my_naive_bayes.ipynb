{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from math import log, exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(values):\n",
    "    output = []\n",
    "    seen = set()\n",
    "    for value in values:\n",
    "        # If value has not been encountered yet,\n",
    "        # ... add it to both list and set.\n",
    "        if value not in seen:\n",
    "            output.append(value)\n",
    "            seen.add(value)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word(word, bag, aDict, vocab):\n",
    "    product = 1\n",
    "    denom = len(bag) + len(vocab)\n",
    "    \n",
    "    if(word in vocab):\n",
    "        if(word in bag):\n",
    "            num = aDict[word]+1\n",
    "        else:\n",
    "            num = 1\n",
    "        \n",
    "        wordProb = num/denom\n",
    "        \n",
    "        return wordProb\n",
    "    \n",
    "    else:\n",
    "        wordProb = 1\n",
    "        return wordProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_naive_bayes(testfile):\n",
    "    filenames = ['imdb_labelled.txt','yelp_labelled.txt','amazon_cells_labelled.txt']\n",
    "    \n",
    "    docSent = []\n",
    "    docVocab = []\n",
    "    \n",
    "    negVocab = []\n",
    "    posVocab = []\n",
    "    \n",
    "    negCount = 0\n",
    "    posCount = 0\n",
    "    \n",
    "    with open('train.txt','w') as outfile:\n",
    "        for file in filenames:\n",
    "            with open(file) as infile:\n",
    "                for line in infile:\n",
    "                    outfile.write(line)\n",
    "    \n",
    "    with open('train.txt','r') as g:\n",
    "        for line in g:\n",
    "            line = line.lower()\n",
    "            line = line.strip('\\n')\n",
    "            line = line.replace('\\t',' ')\n",
    "            \n",
    "            if('0' in line):\n",
    "                line = line[0:len(line)-1]\n",
    "                inter = line.split()\n",
    "                negVocab = negVocab + inter\n",
    "                negCount +=1\n",
    "                \n",
    "            elif('1' in line):\n",
    "                line = line[0:len(line)-1]\n",
    "                inter = line.split()\n",
    "                posVocab = posVocab + inter\n",
    "                posCount += 1\n",
    "                \n",
    "            line = line[0:len(line)-1]    \n",
    "            docSent.append(line)\n",
    "            docVocab = docVocab + line.split()\n",
    "        \n",
    "        docVocab = remove_duplicates(docVocab)\n",
    "        \n",
    "        total = len(docSent)\n",
    "        probNeg = negCount/total\n",
    "        probPos = posCount/total\n",
    "        \n",
    "        negDict = {}\n",
    "        posDict = {}\n",
    "        \n",
    "        for word in negVocab:\n",
    "            if word in negDict:\n",
    "                negDict[word] = negDict[word] + 1\n",
    "            else:\n",
    "                negDict[word] = 1\n",
    "        \n",
    "        for word in posVocab:\n",
    "            if word in posDict:\n",
    "                posDict[word] = posDict[word] + 1\n",
    "            else:\n",
    "                posDict[word] = 1\n",
    "    \n",
    "    features = []\n",
    "    mulArrayNeg = []\n",
    "    mulArrayPos = []\n",
    "    \n",
    "    probArray = []\n",
    "    results = open('results.txt','w')\n",
    "    with open(testfile,'r') as k:\n",
    "        for line in k:\n",
    "            print(line)\n",
    "            features = features + line.split()\n",
    "\n",
    "            prodNeg = 1\n",
    "            prodPos = 1\n",
    "            maxDict = {}\n",
    "            negProbArray = []\n",
    "            posProbArray = []\n",
    "            for word in features:\n",
    "                \n",
    "                #check word\n",
    "                negProbArray.append(check_word(word, negVocab, negDict, docVocab))\n",
    "                posProbArray.append(check_word(word, posVocab, posDict, docVocab))\n",
    "            \n",
    "            for i in negProbArray:\n",
    "                prodNeg *= i\n",
    "            for i in posProbArray:\n",
    "                prodPos *= i\n",
    "            prodNeg = prodNeg * probNeg\n",
    "            prodPos = prodPos * probPos\n",
    "            \n",
    "            maxDict[\"0\"] = prodNeg\n",
    "            maxDict[\"1\"] = prodPos\n",
    "            \n",
    "            maximum = max(maxDict, key=maxDict.get) \n",
    "            \n",
    "            results.write(line.strip('\\n') + '\\t' + maximum + '\\n')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictable with no fun\n",
      "\n",
      "loved it\n",
      "\n",
      "it was okay\n"
     ]
    }
   ],
   "source": [
    "my_naive_bayes('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
